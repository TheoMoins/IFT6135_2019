{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distribution2(batch_size=512):\n",
    "    # High dimension uniform distribution\n",
    "    while True:\n",
    "        yield(np.random.uniform(0, 1, (batch_size, 2)))\n",
    "        \n",
    "\n",
    "def distribution1(x, batch_size=512):\n",
    "    # Distribution defined as (x, U(0,1)). Can be used for question 3\n",
    "    while True:\n",
    "        yield(np.array([(x, random.uniform(0, 1)) for _ in range(batch_size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def JSD_objective(D,x,y):\n",
    "    D_x = D.forward(x)\n",
    "    D_y = D.forward(y)\n",
    "    return math.log(2) + 0.5 * (torch.mean(torch.log(D_x))) +  0.5 * (torch.mean(torch.log(1 - D_y)))\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, x, y):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((x.size(0), 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * x + ((1 - alpha) * y)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(x.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WD_gp_objective(D, x , y):\n",
    "       \n",
    "    lambda_gp = 10\n",
    "    D_x = D.forward(x)\n",
    "    D_y = D.forward(y)\n",
    "    return torch.mean(D_x) - torch.mean(D_y) - lambda_gp * compute_gradient_penalty(D, x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_input_size = 2\n",
    "d_hidden_size = 75   \n",
    "d_output_size = 1\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.elu = torch.nn.ELU()\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.map1(x))\n",
    "        x = self.elu(self.map2(x))\n",
    "        return torch.sigmoid( self.map3(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "d_optimizer = optim.SGD(D.parameters(), lr=0.001 ) \n",
    "def distance_estimate(dist1, dist2, n_epochs = 1000, Wasserstein = False):\n",
    "#    losses = []\n",
    "    if Wasserstein:\n",
    "        objective = WD_gp_objective\n",
    "    else:\n",
    "        objective = JSD_objective\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        samplesx = next(dist1)\n",
    "        samplesy = next(dist2)\n",
    "        \n",
    "        x =torch.from_numpy(samplesx).float() #realdata\n",
    "        y = torch.from_numpy(samplesy).float()\n",
    "        d_optimizer.zero_grad()\n",
    "        loss_D = -objective(D, x, y)\n",
    "        loss_D.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "#        losses.append(-loss_W.item())\n",
    "\n",
    "    return -loss_D.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0727398693561554\n",
      "0.14052468538284302\n",
      "0.1943548619747162\n",
      "0.23627428710460663\n",
      "0.26424404978752136\n",
      "0.2766450047492981\n",
      "0.2694860100746155\n",
      "0.24174611270427704\n",
      "0.18804693222045898\n",
      "0.10565412044525146\n",
      "-0.0002110004425048828\n",
      "-0.10906785726547241\n",
      "-0.18836838006973267\n",
      "-0.2187577188014984\n",
      "-0.20818832516670227\n",
      "-0.16920223832130432\n",
      "-0.11783340573310852\n",
      "-0.0604877769947052\n",
      "0.0035831034183502197\n",
      "0.08092963695526123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f19e80db588>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist1 = iter(distribution1(0))\n",
    "\n",
    "n_epochs = 400\n",
    "\n",
    "y_axis_JSD = []\n",
    "y_axis_W = []\n",
    "phi = np.arange(-1,1,0.1)\n",
    "\n",
    "for i in range(len(phi)):\n",
    "\n",
    "    dist1 = iter(distribution1(0))\n",
    "    dist2 = iter(distribution1(phi[i]))\n",
    "\n",
    "    \n",
    "    e = distance_estimate(dist1, dist2, n_epochs, False)\n",
    "    print(e)\n",
    "    \n",
    "    y_axis_JSD.append(e)\n",
    "    \n",
    "#    y_axis_W.append(distance_estimate(dist1, dist2, n_epochs, True))\n",
    "\n",
    "plt.plot(phi, y_axis_JSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
