{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load('mnist.npz')\n",
    "x_train, y_train = data['x_train'], data['y_train']\n",
    "x_test, y_test = data['x_test'], data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to vectors, change dtype from int8 to float32 and normalize [0,255] -> [0,1]\n",
    "x_train = x_train.reshape(x_train.shape[0], -1).astype(np.float32) / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], -1).astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Classifier(object):\n",
    "    def __init__(self,hidden_dims=(500,100),n_hidden=2,mode='train',datapath=None,model_path=None):\n",
    "        #weights and bias structure\n",
    "        self.weights, self.bias = [], []\n",
    "        #layer 1\n",
    "        self.weights.append(np.empty((784, hidden_dims[0])))\n",
    "        self.bias.append(np.zeros((hidden_dims[0])))\n",
    "        #hidden layer\n",
    "        for i in range(n_hidden - 1):\n",
    "            self.weights.append(np.empty((hidden_dims[i], hidden_dims[i+1])))\n",
    "            self.bias.append(np.zeros((hidden_dims[i+1])))\n",
    "        #output layer\n",
    "        self.weights.append(np.empty((hidden_dims[-1], 10)))\n",
    "        self.bias.append(np.zeros((10)))\n",
    "    \n",
    "    def initialize_weights(self,method='glorot'):\n",
    "        for i, w in enumerate(self.weights):\n",
    "            if method is 'glorot':\n",
    "                d = math.sqrt(6/(w.shape[0]+w.shape[1]))\n",
    "                self.weights[i]=np.random.uniform(low=-d, high=d, size=w.shape)\n",
    "            if method is 'normal':\n",
    "                self.weights[i]=np.random.normal(loc=0, scale=1, size=w.shape)\n",
    "            if method is 'zero':\n",
    "                self.weights[i]=np.zeros(shape=w.shape)\n",
    "    \n",
    "    def forward(self,input):\n",
    "        self.cache = [input]\n",
    "        for w, b in zip(self.weights, self.bias):\n",
    "            self.cache.append(self.activation(self.cache[-1] @ w + b))\n",
    "        return self.softmax(self.cache.pop())\n",
    "    \n",
    "    def activation(self,input):\n",
    "        return np.maximum(0, input)\n",
    "    \n",
    "    def loss(self, prediction, label):\n",
    "        return -math.log(prediction[label])\n",
    "\n",
    "    def softmax(self, input):\n",
    "        return np.exp(input)/np.sum(np.exp(input))\n",
    "    \n",
    "    def backward(self, output, label):\n",
    "        grad_pre_activation = np.asarray([o-1 if o==label else o for o in output])\n",
    "        self.grad_w, self.grad_b = [], []\n",
    "        # we go from the last layer to the first one\n",
    "        for i, (w, b) in enumerate(zip(reversed(self.weights), reversed(self.bias))):\n",
    "            gw = np.asarray(list(reversed(self.cache))[i]).reshape(-1,1) @ grad_pre_activation.reshape(1,-1)\n",
    "            self.grad_w.insert(0, gw)\n",
    "            self.grad_b.insert(0, grad_pre_activation)\n",
    "            grad_previous_hidden_layer = w @ grad_pre_activation\n",
    "            grad_pre_activation = grad_previous_hidden_layer * [1 if x>0 else 0 for x in list(reversed(self.cache))[i]]\n",
    "            \n",
    "    def update(self):\n",
    "        lr = 0.01\n",
    "        for i, (gw, gb) in enumerate(zip(self.grad_w, self.grad_b)):\n",
    "            self.weights[i] = self.weights[i] - lr * gw\n",
    "            self.bias[i] = self.bias[i] - lr * gb\n",
    "\n",
    "    def train(self, inputs, labels, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            print(\"epoch {}\".format(epoch))\n",
    "            for i, (x, y) in enumerate(zip(inputs, labels),1):\n",
    "                pred = clf.forward(x)\n",
    "                if i%10 == 0:\n",
    "                    print(\"\\t{}: {:.3f}\".format(i, clf.loss(pred, y)))\n",
    "                if math.isnan(clf.loss(pred, y)):\n",
    "                    break\n",
    "                clf.backward(pred, y)\n",
    "                clf.update()\n",
    "\n",
    "    def test(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "clf.initialize_weights('glorot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.backward(clf.forward(x_train[0]), y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "\t10: 2.310\n",
      "\t20: 2.303\n",
      "\t30: 2.303\n",
      "\t40: 2.303\n",
      "\t50: 2.303\n",
      "\t60: 2.303\n",
      "\t70: 2.303\n",
      "\t80: 2.303\n",
      "\t90: 2.303\n",
      "\t100: 2.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quentin/pytorch-env/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in matmul\n",
      "/home/quentin/pytorch-env/lib/python3.6/site-packages/ipykernel_launcher.py:48: RuntimeWarning: overflow encountered in matmul\n",
      "/home/quentin/pytorch-env/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: overflow encountered in matmul\n",
      "/home/quentin/pytorch-env/lib/python3.6/site-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in matmul\n",
      "/home/quentin/pytorch-env/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "/home/quentin/pytorch-env/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/quentin/pytorch-env/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in matmul\n"
     ]
    }
   ],
   "source": [
    "clf.train(x_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
